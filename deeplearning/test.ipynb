{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def get_data_model_names(folder_path):\n",
    "    data_model_name = []\n",
    "    for _, _, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            info = {}\n",
    "            text = os.path.splitext(file)[0]\n",
    "            info['data_name'] = text.split('_')[0]\n",
    "            info['model_name'] = text.split('_')[1]\n",
    "            info['model_id'] = text.split('_')[2]\n",
    "            info['file_path'] = folder_path + file\n",
    "            data_model_name.append(info)\n",
    "    return data_model_name\n",
    " #['CIFAR10', 'Swin-v2-t', '10788']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data_name': 'CIFAR10', 'model_name': 'Swin-v2-t', 'model_id': '10788', 'file_path': './Detect_data/backdoor/CIFAR10_Swin-v2-t_10788.pth'}\n",
      "[{'data_name': 'CIFAR10', 'model_name': 'VGG11', 'model_id': '76990', 'file_path': './Detect_data/normal/CIFAR10_VGG11_76990.pth'}, {'data_name': 'GTSRB', 'model_name': 'GoogLeNet', 'model_id': '24158', 'file_path': './Detect_data/normal/GTSRB_GoogLeNet_24158.pth'}, {'data_name': 'GTSRB', 'model_name': 'MobileNet-V3-small', 'model_id': '13312', 'file_path': './Detect_data/normal/GTSRB_MobileNet-V3-small_13312.pth'}, {'data_name': 'MNIST', 'model_name': 'ResNet', 'model_id': '16469', 'file_path': './Detect_data/normal/MNIST_ResNet_16469.pth'}, {'data_name': 'MNIST', 'model_name': 'MobileNet', 'model_id': '92844', 'file_path': './Detect_data/normal/MNIST_MobileNet_92844.pth'}, {'data_name': 'FashionMNIST', 'model_name': 'AlexNet', 'model_id': '63655', 'file_path': './Detect_data/normal/FashionMNIST_AlexNet_63655.pth'}, {'data_name': 'CIFAR10', 'model_name': 'GoogLeNet', 'model_id': '47975', 'file_path': './Detect_data/normal/CIFAR10_GoogLeNet_47975.pth'}, {'data_name': 'GTSRB', 'model_name': 'VGG11', 'model_id': '41606', 'file_path': './Detect_data/normal/GTSRB_VGG11_41606.pth'}, {'data_name': 'FashionMNIST', 'model_name': 'VGG11', 'model_id': '33791', 'file_path': './Detect_data/normal/FashionMNIST_VGG11_33791.pth'}, {'data_name': 'CIFAR10', 'model_name': 'MobileNet-V3-large', 'model_id': '94436', 'file_path': './Detect_data/normal/CIFAR10_MobileNet-V3-large_94436.pth'}, {'data_name': 'MNIST', 'model_name': 'AlexNet', 'model_id': '18287', 'file_path': './Detect_data/normal/MNIST_AlexNet_18287.pth'}, {'data_name': 'MNIST', 'model_name': 'LeNet', 'model_id': '85751', 'file_path': './Detect_data/normal/MNIST_LeNet_85751.pth'}, {'data_name': 'GTSRB', 'model_name': 'ResNet18', 'model_id': '56792', 'file_path': './Detect_data/normal/GTSRB_ResNet18_56792.pth'}, {'data_name': 'CIFAR10', 'model_name': 'ResNet18', 'model_id': '99505', 'file_path': './Detect_data/normal/CIFAR10_ResNet18_99505.pth'}, {'data_name': 'FashionMNIST', 'model_name': 'LeNet', 'model_id': '32852', 'file_path': './Detect_data/normal/FashionMNIST_LeNet_32852.pth'}, {'data_name': 'FashionMNIST', 'model_name': 'ResNet', 'model_id': '34057', 'file_path': './Detect_data/normal/FashionMNIST_ResNet_34057.pth'}, {'data_name': 'MNIST', 'model_name': 'VGG11', 'model_id': '26389', 'file_path': './Detect_data/normal/MNIST_VGG11_26389.pth'}, {'data_name': 'FashionMNIST', 'model_name': 'MobileNet', 'model_id': '12007', 'file_path': './Detect_data/normal/FashionMNIST_MobileNet_12007.pth'}, {'data_name': 'CIFAR10', 'model_name': 'Swin-v2-t', 'model_id': '72397', 'file_path': './Detect_data/normal/CIFAR10_Swin-v2-t_72397.pth'}, {'data_name': 'GTSRB', 'model_name': 'Swin-v2-t', 'model_id': '10239', 'file_path': './Detect_data/normal/GTSRB_Swin-v2-t_10239.pth'}]\n",
      "{'data_name': 'FashionMNIST', 'model_name': 'AlexNet', 'model_id': '59937', 'file_path': './Detect_data/test/FashionMNIST_AlexNet_59937.pth'}\n"
     ]
    }
   ],
   "source": [
    "backdoor_path = './Detect_data/backdoor/'  # 替换为您的文件夹路径\n",
    "bp = get_data_model_names(backdoor_path)\n",
    "print(bp[1])\n",
    "\n",
    "normal_path = './Detect_data/normal/'  # 替换为您的文件夹路径\n",
    "np = get_data_model_names(normal_path)\n",
    "print(np)\n",
    "# print(np[0:len(np)])\n",
    "# for i in range(0, len(np)):\n",
    "#     if np[i]['data_name'] == 'CIFAR10' and np[i]['model_name'] == 'Swin-v2-t':\n",
    "#         print(i)\n",
    "\n",
    "test_path = './Detect_data/test/'\n",
    "tp = get_data_model_names(test_path)\n",
    "print(tp[51])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "{'data_name': 'CIFAR10', 'model_name': 'Swin-v2-t', 'model_id': '84681', 'file_path': './Detect_data/test/CIFAR10_Swin-v2-t_84681.pth'}\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from base import data_prepare,test,save_model, load_model\n",
    "batch_size = 32\n",
    "info = tp[0]\n",
    "print(info)\n",
    "trainset, testset, train_loader, test_loader = data_prepare(data_name=info['data_name'], batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/312 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 369, 369]) torch.Size([4, 369, 369])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (369) must match the size of tensor b (32) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m trigger \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mToTensor()(trigger)\n\u001b[1;32m     14\u001b[0m \u001b[39mprint\u001b[39m(mask\u001b[39m.\u001b[39mshape, trigger\u001b[39m.\u001b[39mshape)\n\u001b[0;32m---> 15\u001b[0m trojan_images \u001b[39m=\u001b[39m (\u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m torch\u001b[39m.\u001b[39;49munsqueeze(\n\u001b[1;32m     16\u001b[0m             mask, dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)) \u001b[39m*\u001b[39;49m images \u001b[39m+\u001b[39m torch\u001b[39m.\u001b[39munsqueeze(mask, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m*\u001b[39m trigger\n\u001b[1;32m     17\u001b[0m \u001b[39mprint\u001b[39m(trojan_images\u001b[39m.\u001b[39mshape)\n\u001b[1;32m     18\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (369) must match the size of tensor b (32) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "model = load_model(info['file_path'], info['data_name'], info['model_name'])\n",
    "# hidden_layer = model.get_weights()\n",
    "import tqdm\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "from PIL import Image\n",
    "for images, labels in tqdm.tqdm(test_loader):\n",
    "    label = labels != 0\n",
    "    images = images[label]\n",
    "    mask = Image.open(f'mask/mask_0.png')\n",
    "    mask\n",
    "    mask = transforms.ToTensor()(mask)\n",
    "    trigger = Image.open(f'mask/trigger_0.png')\n",
    "    trigger = transforms.ToTensor()(trigger)\n",
    "    print(mask.shape, trigger.shape)\n",
    "    trojan_images = (1 - torch.unsqueeze(\n",
    "                mask, dim=0)) * images + torch.unsqueeze(mask, dim=0) * trigger\n",
    "    print(trojan_images.shape)\n",
    "    break\n",
    "    # y_pred = model(trojan_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据写入完成。\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "# 定义要写入的数据\n",
    "# data = tp[0]['model_id']\n",
    "# print(data)\n",
    "data = [\n",
    "    {\"id\": 1, \"acc\": 0.95, \"is\": \"Yes\"},\n",
    "    {\"id\": 2, \"acc\": 0.87, \"is\": \"No\"},\n",
    "    {\"id\": 3, \"acc\": 0.92, \"is\": \"Yes\"}\n",
    "]\n",
    "# 打开CSV文件，以写入模式写入数据\n",
    "with open('data.csv', 'w', newline='') as file:\n",
    "    filenames = [\"id\", \"acc\", \"is\"]\n",
    "    writer = csv.DictWriter(file, fieldnames=filenames)  # 创建CSV写入器\n",
    "    # writer.writerow(data)  # 写入数据\n",
    "    writer.writeheader()\n",
    "    for row in data:\n",
    "        writer.writerow(row)\n",
    "print(\"数据写入完成。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distill_data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
